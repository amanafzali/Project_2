{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to get show started\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from numpy.random import seed\n",
    "from pathlib import Path\n",
    "\n",
    "# Import required preprocessing and Keras modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO after model experimentation\n",
    "# Define random seed for reproducibility\n",
    "\n",
    "# seed(1)\n",
    "# random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in prepared model dataset created in data_prep notebook\n",
    "\n",
    "model_df = pd.read_csv(Path('./ModelData/model_dataset.csv'),index_col=\"Date_Time\",infer_datetime_format=True,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 35513 entries, 2017-01-01 00:00:00 to 2021-01-15 00:00:00\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   US_Market_Open        35513 non-null  float64\n",
      " 1   Trail24hr_CloseRatio  35513 non-null  float64\n",
      " 2   Trail12Wk_CloseRatio  35513 non-null  float64\n",
      " 3   Trail52Wk_CloseRatio  35513 non-null  float64\n",
      " 4   Hr_Return             35513 non-null  float64\n",
      " 5   Trail24hr_Return      35513 non-null  float64\n",
      " 6   Trail24hr_Std         35513 non-null  float64\n",
      " 7   Trail12Wk_Return      35513 non-null  float64\n",
      " 8   Trail12Wk_Std         35513 non-null  float64\n",
      " 9   Trail52Wk_Return      35513 non-null  float64\n",
      " 10  Trail52Wk_Std         35513 non-null  float64\n",
      " 11  Trail24hr_VolRatio    35513 non-null  float64\n",
      " 12  Trail12Wk_VolRatio    35513 non-null  float64\n",
      " 13  Trail52Wk_VolRatio    35513 non-null  float64\n",
      " 14  Vol_PctDelta          35513 non-null  float64\n",
      " 15  Bitcoin Trend         35513 non-null  float64\n",
      " 16  Cryptocurrency        35513 non-null  float64\n",
      " 17  crypto all time high  35513 non-null  float64\n",
      " 18  crypto drop           35513 non-null  float64\n",
      " 19  btc halving           35513 non-null  float64\n",
      " 20  Significant_Drawdown  35513 non-null  int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Last minute pruning of unwanted columns\n",
    "\n",
    "#####################################################################\n",
    "# CRITICAL TO MATCH SAME COLUMNS AS USED IN TRAIN NOTEBOOK FOR THIS \n",
    "# MODEL. THE SAME PROCESS IS USED HERE TO RECREATE THE TEST DATASET\n",
    "#####################################################################\n",
    "\n",
    "#  remove Close price, US holiday\n",
    "column_2drop_list = ['Close',\n",
    "                     'Volume',\n",
    "                     'US_Holiday']\n",
    "\n",
    "model_df = model_df.drop(columns=column_2drop_list)\n",
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_window_chopper(df, window_len, feature_col_numlist, target_col_num):\n",
    "    \"\"\"\n",
    "    Function chops up dataframe features (X) defined by column numbers\n",
    "    in feature_col_numlist and target (y) values defined by t_col_num\n",
    "    with a rolling window of length window_len.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window_len):\n",
    "        feature_list = []\n",
    "        for feature_col_num in feature_col_numlist:\n",
    "            feature_list.append(df.iloc[i:(i + window_len), feature_col_num])\n",
    "        X.append(feature_list)\n",
    "        y.append(df.iloc[(i + window_len), target_col_num])\n",
    "    return np.array(X).reshape(-1,(len(feature_col_numlist)*window_len)), np.array(y).reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features (X) and target (y) data window sets\n",
    "\n",
    "window_size = 12 # model dataset is hourly, try half day for starters\n",
    "feature_col_numlist = list(range(model_df.shape[1]-1))\n",
    "target_col_num = (model_df.shape[1] - 1) # 0s based column index\n",
    "X, y = data_window_chopper(model_df, window_size, feature_col_numlist, target_col_num)\n",
    "\n",
    "#print(f\"X sample values:\\n {X[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70% of the data for training, 30% for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras LSTM API requires features data as a vertical vector\n",
    "\n",
    "# reshape training and test data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#print (f\"X_train sample values:\\n{X_train[:2]} \\n\")\n",
    "#print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model state from train notebook to proceed with eval\n",
    "\n",
    "saved_model = keras.models.load_model(\"./Model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 21s 63ms/step - loss: 0.0043 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004344658460468054, 0.9997183084487915]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model performance with test data\n",
    "\n",
    "saved_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Create graphs and eval here.\n",
    "# note will need to reload Close price data as it was dropped prior to train, test vector creation!\n",
    "\n",
    "\"\"\"\n",
    "Graphs to show:\n",
    "1- loss reduction?\n",
    "\n",
    "2- closing price vs actual drawdowns vs predicted drawdowns\n",
    "    great if this can be shown all in one graph with predicted of course starting later on in time\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
